+++
date = "2017-04-30"
tags = ["udacity","deep learning", "tensorflow", "google"]
title = "Deep Learning"
draft=true
description = "Introduce you to deep learning by google's experts"
topics = ["Development"]

+++
Please find the corresponding udacity course [here] (
https://www.udacity.com/course/deep-learning--ud730).

# Table of Contents
1. [Basics](#basics)
1. [Neural Networks](#neural-networks)
1. [Models](#models)
1. [Software and Tools](#software-and-tools)

# Basics 

Classification = Give an input a label

After having classified things, it's easy to work with them. Ex.: Detection, Ranking, Regression, Reinforcement learning.

Training set = a lot of examples

Logistic classifier/linear classifier = applies a linear function to the input

Keep the size of your outputs big, to get confident predictions.

Classifiers should be unconfident in the beginning and gai confidence as the model learns.

One-Hot Encoding means a vector with one 1 for the biggest value and only zeros else.

1-Hot Encoding works very well for most of problems. It becomes inefficient it you have a large number of classes, then use embeddings.

Cross Entropy = Mesure distance between two probability vectors. Is asymetric = labels and distributions have to be in the right place.

**Multinomial logistic classification**: input -(linear model)-> logit -(softmax)-> probabilities -(cross-entropy)-> 1-Hot labels

Loss = Average cross-entropy, should be small.

Mean should be 0. Variance should be equal between variables.

## What is Deep Learning?

## notMNIST

# Neural Networks

## Deep

## Convolutional

# Models

## Embeddings

## Recurrent Models

# Software and Tools
